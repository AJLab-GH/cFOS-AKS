---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: ollama
  namespace: cluster-config
spec:
  targetNamespace: ollama
  releaseName: ollama
  chart:
    spec:
      chart: ollama
      sourceRef:
        kind: HelmRepository
        name: ollama
        namespace: cluster-config
      version: "0.x"
  interval: 10m0s
  install:
    timeout: 20m
    remediation:
      retries: 5
  upgrade:
    timeout: 20m
  values:
    resources:
      requests: {}
      limits:
        nvidia.com/gpu: 0
    image:
      tag: "0.2.2"
    gpu:
      enabled: true
    ollama:
      gpu:
        enabled: true
      models:
        - deepseek-coder-v2:16b-lite-base-q6_K
        - llama3:70b
        - nomic-embed-text
        - mistral:7b-instruct-q8_0
        - codestral:22b-v0.1-q6_K
        - codestral:latest
    extraEnv:
      - name: OLLAMA_KEEP_ALIVE
        value: "-1"
    ingress:
      enabled:
      hosts:
        - host: www.bankexample.com
          paths:
            - path: /
              pathType: Prefix
    persistentVolume:
      enabled: true
      size: 100Gi
    tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
